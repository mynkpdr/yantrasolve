---
title: Yantrasolve
emoji: ğŸ¢
colorFrom: blue
colorTo: green
sdk: docker
pinned: false
license: mit
short_description: An automated system that to solve data-driven quizzes.
---

# ğŸ§© YantraSolve â€“ Automated Quiz Solver

[![Hugging Face Space](https://img.shields.io/badge/ğŸ¤—-Space-ff5c5c?logo=huggingface)](https://huggingface.co/spaces/mynkpdriitm/yantrasolve)
[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](https://opensource.org/licenses/MIT)
[![Python](https://img.shields.io/badge/python-3.12%2B-blue)](https://www.python.org/)

**Author:** Mayank Kumar Poddar (<23f3004197@ds.study.iitm.ac.in>)  
**GitHub:** [mayanklearns/yantrasolve](https://github.com/mayanklearns/yantrasolve)

---

## ğŸ“– Overview

`YantraSolve` is a **FastAPIâ€‘based microâ€‘service** that automatically solves the *LLM Analysis Quiz* used in the **Tools in Data Science â€“ ProjectÂ 2** of the **IITM BS Degree Programme**.  
The system leverages **LangGraph**, **large language models**, and a **headless Chromium browser** to:

1. **Fetch** each quiz page (HTML, screenshots, console logs).  
2. **Reason** about the next action using an LLMâ€‘driven agent.  
3. **Execute** Python or JavaScript snippets, download auxiliary files, and finally **submit** the answer payload.
4. **Iterate** until the whole quiz chain is completed.

All heavy lifting happens in a **background task**, allowing the API to respond instantly while the solver works asynchronously.

---

## ğŸš€ Quick Start (Local Development)

### Prerequisites
- **Pythonâ€¯3.11+** (recommended via `uv` â€“ a fast, modern Python package manager).
- **Docker** (optional, for containerised deployment).
- **Playwright** browsers â€“ they are installed automatically when you run the app for the first time.

### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/mayanklearns/yantrasolve.git
cd yantrasolve
```

### 2ï¸âƒ£ Install dependencies with **uv**
```bash
uv sync   # reads pyproject.toml and installs exact versions
```
> `uv sync` creates a virtual environment in `.venv` (by default) and locks the dependency graph, guaranteeing reproducible builds.

### 3ï¸âƒ£ Configure environment variables
Create a `.env` file in the project root (or export variables in your shell). Example:
```dotenv
SECRET_KEY=your-secret-key
STUDENT_EMAIL=23f3004197@ds.study.iitm.ac.in
LLM_API_KEY=your-openai-or-google-api-key
LLM_PROVIDER=google   # or anthropic, openai, etc.
HOST=0.0.0.0
PORT=8000
DEBUG=true
```
> The `settings` module (`app/config/settings.py`) reads these variables via **pydanticâ€‘settings**.

### 4ï¸âƒ£ Run the server
```bash
uv run python -m uvicorn main:app --reload
```
The API will be available at `http://127.0.0.1:8000`.

### 5ï¸âƒ£ Health check
```bash
curl http://127.0.0.1:8000/health
```
You should receive a JSON response confirming the service is up.

---

## ğŸ“¦ Docker & HuggingFace Space Deployment

### Dockerfile (already in the repo)
The repository ships a productionâ€‘ready `Dockerfile`. Build and run it locally:
```bash
docker build -t yantrasolve .

docker run -p 8000:8000 \
  -e SECRET_KEY=your-secret-key \
  -e STUDENT_EMAIL=23f3004197@ds.study.iitm.ac.in \
  -e LLM_API_KEY=your-llm-key \
  -e LLM_PROVIDER=google \
  yantrasolve
```
The container starts the FastAPI app automatically.

### Deploy as a HuggingFace Space (FastAPI template)
1. **Create a new Space** on HuggingFace and select the *FastAPI* template.
2. **Push the repository** to the Space (or use the UI to upload files). The existing `Dockerfile` will be used by HuggingFace to build the container.
3. **Add the required secrets** in the Space settings under *Variables* (`SECRET_KEY`, `STUDENT_EMAIL`, `LLM_API_KEY`, `LLM_PROVIDER`).
4. The Space will automatically start the server on the port defined by the `PORT` env variable (default `8000`).
5. Once the build finishes, you can interact with the API via the Space URL, e.g., `https://mynkpdriitm-yantrasolve.hf.space/quiz`.

> **Note:** HuggingFace Spaces enforce a 12â€‘hour timeout for background tasks. The solver is designed to finish well within this limit (default 1â€‘hour timeout per quiz chain).

---

## ğŸŒ² Project Structure
```
.
â”œâ”€â”€ app/                     # Core application package
â”‚   â”œâ”€â”€ config/              # Settings (pydantic)
â”‚   â”œâ”€â”€ graph/               # LangGraph construction
â”‚   â”œâ”€â”€ nodes/               # Graph nodes (fetch, agent, submit, â€¦)
â”‚   â”œâ”€â”€ resources/           # Browser, LLM, API helpers
â”‚   â”œâ”€â”€ tools/               # Sandbox tools (python, js, download, submit)
â”‚   â””â”€â”€ utils/               # Helpers & logging
â”œâ”€â”€ tests/                   # pytest suite
â”œâ”€â”€ Dockerfile               # Multiâ€‘stage build for production
â”œâ”€â”€ pyproject.toml           # Build system, dependencies, uv scripts
â”œâ”€â”€ README.md                # You are reading it!
â””â”€â”€ main.py                  # FastAPI entry point
```

### `pyproject.toml`
The **pyproject.toml** defines the build backend, dependencies, and a convenient `uv run` script:
```toml
[project]
name = "yantrasolve"
version = "0.1.0"
description = "Automated quiz solver for IITM Data Science project"
requires-python = ">=3.11"
license = {text = "MIT"}
authors = [{name = "Mayank Kumar Poddar", email = "23f3004197@ds.study.iitm.ac.in"}]

[project.dependencies]
fastapi = "^0.115"
uvicorn = "^0.30"
langgraph = "^0.0.30"
playwright = "^1.45"
pydantic-settings = "^2.5"
# â€¦ other runtime deps â€¦

[tool.uv]
# uv specific configuration (optional)

[tool.uv.scripts]
start = "python -m uvicorn main:app --host $HOST --port $PORT"
```
Running `uv sync` reads this file, creates a lockfile (`uv.lock`) and installs the exact versions, guaranteeing reproducibility across environments.

---

## ğŸ“š API Specification

| Method | Path | Description | Request Body | Response |
|--------|------|-------------|--------------|----------|
| `GET` | `/` or `/health` | Health check | â€“ | `{ "status": "ok", "message": "Quiz Solver is running" }` |
| `POST` | `/quiz` | Submit a quizâ€‘solving job (runs in background) | `QuizRequest` (see below) | `{ "status": "accepted", "message": "Quiz solving started" }` |

### `QuizRequest` model
```json
{
  "email": "student@example.com",
  "secret": "your-secret-key",
  "url": "https://tdsbasictest.vercel.app/quiz/1"
}
```
The request is validated against the **Pydantic** model defined in `main.py`.

---

## ğŸ› ï¸ Core Components (highâ€‘level)
- **`app.graph.graph`** â€“ builds the LangGraph workflow (`create_quiz_graph`).
- **`app.nodes.*`** â€“ individual graph nodes (`fetch`, `agent`, `submit`, `feedback`).
- **`app.tools.*`** â€“ sandboxed tools (`python_tool`, `javascript_tool`, `download_file_tool`, `submit_answer_tool`).
- **`app.resources.browser`** â€“ Playwright wrapper for headless Chromium interactions.
- **`app.resources.llm`** â€“ providerâ€‘agnostic LLM client (Google, Anthropic, OpenAI, â€¦).
- **`app.utils.helpers`** â€“ temporaryâ€‘directory management and cleanup utilities.
- **`app.utils.logging`** â€“ structured logging with timestamps.

---

## ğŸ§ª Testing

The repository includes a **pytest** suite under `tests/`.
```bash
uv run pytest -q
```
Key test modules:
- `tests/test_resources/test_api.py` â€“ API endpoint sanity checks.
- `tests/test_resources/test_browser.py` â€“ Playwright launch & navigation sanity.
- `tests/test_resources/test_llm.py` â€“ Mocked LLM responses.

---

## ğŸ¤ Contributing

Contributions are welcome! Please follow these steps:
1. Fork the repository.
2. Create a feature branch (`git checkout -b feature/awesomeâ€‘thing`).
3. Ensure code passes linting (`ruff .`) and tests.
4. Open a Pull Request with a clear description of the changes.

---

## ğŸ“œ License

This project is licensed under the **MIT License** â€“ see the `LICENSE` file for details.

---

## ğŸ“ Contact

- **Name:** Mayank Kumar Poddar
- **Email:** 23f3004197@ds.study.iitm.ac.in
- **GitHub:** https://github.com/mayanklearns/yantrasolve

Feel free to open an issue on GitHub for bugs, feature requests, or general questions.

---

*Happy solving!*
